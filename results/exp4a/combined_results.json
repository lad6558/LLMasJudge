{
  "experiment": "4a",
  "description": "Testing temperature effects on human preference alignment",
  "parameters": {
    "cutoff": 10
  },
  "results": {
    "baseline_accuracy": 0.65,
    "temperatures": [
      0.0,
      0.1,
      0.2,
      0.30000000000000004,
      0.4,
      0.5,
      0.6000000000000001,
      0.7000000000000001,
      0.8,
      0.9,
      1.0
    ],
    "no_reasoning": {
      "0.0": 0.7,
      "0.1": 0.7,
      "0.2": 0.7,
      "0.30000000000000004": 0.7,
      "0.4": 0.7,
      "0.5": 0.7,
      "0.6000000000000001": 0.7,
      "0.7000000000000001": 0.7,
      "0.8": 0.7,
      "0.9": 0.7,
      "1.0": 0.7
    },
    "with_reasoning": {
      "0.0": 0.75,
      "0.1": 0.75,
      "0.2": 0.75,
      "0.30000000000000004": 0.75,
      "0.4": 0.75,
      "0.5": 0.75,
      "0.6000000000000001": 0.75,
      "0.7000000000000001": 0.75,
      "0.8": 0.75,
      "0.9": 0.75,
      "1.0": 0.75
    },
    "method_comparison": {
      "Pairwise\nbaseline": 0.65,
      "GPT-4o-mini\nbasic": 0.7,
      "GPT-4o-mini\nw/reasoning": 0.75,
      "GPT-4o-mini\nw/reasoning after": 0.75,
      "GPT-4o-mini\n10 trials": 0.7,
      "GPT-4o-mini\nw/reasoning\n10 trials": 0.75,
      "GPT-4o\nbasic": 0.7,
      "GPT-3.5-turbo\nw/reasoning\n10 trials": 0.75
    }
  }
}